{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 反向传播\n",
    "\n",
    "前面几个小节我们学习了构建计算图、构建层次结构的图并进行计算，或者说“预测”，因为这个过程权重是没有发生改变的。\n",
    "\n",
    "还学习了用于数值预测或者说连续型数据预测的代价函数和用于分类预测的代价函数。\n",
    "\n",
    "那么这个小节，我们就通过两个例子，综合前面所学习的内容，来感受一波训练过程。其实训练过程就是一个“反向传播，权重更新”的过程。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一个回归的例子\n",
    "\n",
    "这个例子就是拟合一个权重10。\n",
    "\n",
    "输入1周围的数，输出10。\n",
    "\n",
    "待训练权重A，满足： 输入*A = 输出。 显然A等于10。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义graph、损失函数\n",
    "x_vals = np.random.normal(1,0.1,100)\n",
    "y_vals = np.repeat(10., 100)\n",
    "x_data = tf.placeholder(tf.float32, shape=[1])\n",
    "y_label = tf.placeholder(tf.float32, shape=[1])\n",
    "\n",
    "A = tf.get_variable('weight',initializer=tf.random_normal(shape=[1]))\n",
    "\n",
    "predict = tf.multiply(x_data,A)\n",
    "loss = tf.square(predict - y_label)\n",
    "\n",
    "# 定义训练步骤\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.02) # 采用梯度下降方法来进行求最优解，学习率为0.02\n",
    "train_step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, A = 1.3105\n",
      "Loss = 74.901772\n",
      "Step 25, A = 6.8252\n",
      "Loss = 6.829202\n",
      "Step 50, A = 8.7640\n",
      "Loss = 4.299357\n",
      "Step 75, A = 9.5845\n",
      "Loss = 0.439925\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "init = tf.global_variables_initializer() # 初始化定义的变量\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(100):\n",
    "    rand_idx = np.random.choice(100)\n",
    "    sess.run(train_step, feed_dict={x_data:[x_vals[rand_idx]], y_label:[y_vals[rand_idx]]})\n",
    "    if i % 25 == 0:\n",
    "        print 'Step %d, A = %.4f' % (i, sess.run(A))\n",
    "        print 'Loss = %f' % sess.run(loss, feed_dict={x_data:[x_vals[rand_idx]], y_label:[y_vals[rand_idx]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一个分类的例子\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9c69fc40d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ops.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "# 创建数据、变量\n",
    "x_vals = np.concatenate((np.random.normal(-1, 1, 50), np.random.normal(3, 1, 50)))\n",
    "y_vals = np.concatenate((np.repeat(0., 50), np.repeat(1., 50)))\n",
    "x_data = tf.placeholder(shape=[1], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[1], dtype=tf.float32)\n",
    "\n",
    "A = tf.get_variable('weight', initializer=tf.random_normal(shape=[1]))\n",
    "\n",
    "plt.scatter(x_vals[:50], y_vals[:50], label='1.', color = 'r')\n",
    "plt.scatter(x_vals[50:], y_vals[50:], label='0.', color = 'c')\n",
    "plt.legend(loc = 'upper left')  \n",
    "plt.show()\n",
    "\n",
    "# 定义graph\n",
    "y = tf.add(x_data, A)\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=y, labels=y_target)\n",
    "\n",
    "# 定义训练步骤\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.02) # 采用梯度下降方法来进行求最优解，学习率为0.02\n",
    "train_step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, A = -1.1414\n",
      "Loss = 0.345283\n",
      "Step 25, A = -1.1272\n",
      "Loss = 0.059127\n",
      "Step 50, A = -1.1326\n",
      "Loss = 0.199676\n",
      "Step 75, A = -1.1029\n",
      "Loss = 0.090576\n",
      "Step 100, A = -1.1119\n",
      "Loss = 0.369293\n",
      "Step 125, A = -1.0952\n",
      "Loss = 0.058722\n",
      "Step 150, A = -1.1109\n",
      "Loss = 0.052019\n",
      "Step 175, A = -1.1044\n",
      "Loss = 0.062949\n",
      "Step 200, A = -1.1141\n",
      "Loss = 0.063543\n",
      "Step 225, A = -1.0969\n",
      "Loss = 0.110546\n",
      "Step 250, A = -1.0915\n",
      "Loss = 0.060251\n",
      "Step 275, A = -1.0926\n",
      "Loss = 0.049765\n",
      "Step 300, A = -1.0932\n",
      "Loss = 0.089739\n",
      "Step 325, A = -1.0623\n",
      "Loss = 0.050573\n",
      "Step 350, A = -1.0589\n",
      "Loss = 0.096452\n",
      "Step 375, A = -1.0591\n",
      "Loss = 0.188010\n",
      "Step 400, A = -1.0632\n",
      "Loss = 0.338492\n",
      "Step 425, A = -1.0713\n",
      "Loss = 0.107217\n",
      "Step 450, A = -1.0415\n",
      "Loss = 0.332000\n",
      "Step 475, A = -1.0581\n",
      "Loss = 0.108313\n",
      "Step 500, A = -1.0338\n",
      "Loss = 0.329847\n",
      "Step 525, A = -1.0546\n",
      "Loss = 0.035951\n",
      "Step 550, A = -1.0700\n",
      "Loss = 0.707453\n",
      "Step 575, A = -1.0568\n",
      "Loss = 0.235877\n",
      "Step 600, A = -1.0574\n",
      "Loss = 0.050283\n",
      "Step 625, A = -1.0524\n",
      "Loss = 0.388064\n",
      "Step 650, A = -1.0360\n",
      "Loss = 0.690351\n",
      "Step 675, A = -1.0511\n",
      "Loss = 0.341991\n",
      "Step 700, A = -1.0577\n",
      "Loss = 0.058305\n",
      "Step 725, A = -1.0321\n",
      "Loss = 0.170685\n",
      "Step 750, A = -1.0283\n",
      "Loss = 0.131044\n",
      "Step 775, A = -1.0391\n",
      "Loss = 0.324080\n",
      "Step 800, A = -1.0474\n",
      "Loss = 0.108530\n",
      "Step 825, A = -1.0778\n",
      "Loss = 0.261202\n",
      "Step 850, A = -1.0844\n",
      "Loss = 0.266839\n",
      "Step 875, A = -1.0565\n",
      "Loss = 0.235931\n",
      "Step 900, A = -1.0569\n",
      "Loss = 0.158359\n",
      "Step 925, A = -1.0435\n",
      "Loss = 0.128989\n",
      "Step 950, A = -1.0618\n",
      "Loss = 0.114277\n",
      "Step 975, A = -1.0282\n",
      "Loss = 0.169815\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "init = tf.global_variables_initializer() # 初始化定义的变量\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1000):\n",
    "    rand_idx = np.random.choice(100)\n",
    "    sess.run(train_step, feed_dict={x_data:[x_vals[rand_idx]], y_target:[y_vals[rand_idx]]})\n",
    "    if i % 25 == 0:\n",
    "        print 'Step %d, A = %.4f' % (i, sess.run(A))\n",
    "        print 'Loss = %f' % sess.run(loss, feed_dict={x_data:[x_vals[rand_idx]], y_target:[y_vals[rand_idx]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy = 0.9900\n"
     ]
    }
   ],
   "source": [
    "# 评价\n",
    "predictions = []\n",
    "for idx in range(len(x_vals)):\n",
    "    x_val = [x_vals[idx]]\n",
    "    prediction = sess.run(tf.round(tf.sigmoid(y)), feed_dict={x_data:x_val}) # tf.round(value) 将value转变为最近的整数 \n",
    "    predictions.append(prediction[0])\n",
    "    \n",
    "accuracy = sum(x==y for x,y in zip(predictions, y_vals))/100.0\n",
    "print 'model accuracy = %.4f' % accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
